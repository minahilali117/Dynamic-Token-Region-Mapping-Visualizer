# Dynamic Token-Region Mapping Visualizer

This project provides a visual interpretation of how different words in a multilingual prompt influence the image generated by a Stable Diffusion model. It captures attention maps from the cross-attention layers and produces a token-to-region heatmap overlay.

## Overview

The visualizer enables:

- Extraction of cross-attention weights from a Stable Diffusion model
- Visualization of which words affected which regions in the generated image
- Support for multilingual prompts (e.g., English, Japanese, Spanish)
- Saving or displaying the attention heatmap alongside the generated image

## Key Features:

- Hooks into Stable Diffusion's cross-attention layers
- Supports multilingual prompts (any language supported by the tokenizer)
- Generates both the image and attention visualization
- Creates heatmap showing token-region relationships
- Averages attention across all denoising steps

## Output:

- Generated image
- Attention heatmap showing which tokens influenced which image regions
- Saved visualization combining both

## Notes:

- First run will download the Stable Diffusion model (~4GB)
- Adjust num_inference_steps for quality vs. speed tradeoff
- The heatmap shows token influence on different spatial regions
= Brighter colors indicate stronger attention

You can modify the main() function to use your own prompts
```bash
visualizer = AttentionMapVisualizer()
image, attention, tokens = visualizer.generate_and_visualize(
    prompt="Your prompt here",
    output_path="output.png"
)
```

## Requirements

Install the required dependencies:

```bash
pip install torch diffusers transformers matplotlib seaborn opencv-python
